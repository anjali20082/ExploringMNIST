# -*- coding: utf-8 -*-
"""MLAssignment1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SUqxn8LvZ8E9gFMT6XaAy05hBXVi5Qqt
"""

def importdrive() :
  from google.colab import drive
  drive.mount('/content/drive')
importdrive()

#plot data
def q1a():
  import matplotlib.pyplot as plt
  from matplotlib import cm
  import numpy as np
  from scipy.io import loadmat
  mats = loadmat('/content/drive/My Drive/Colab Notebooks/MLAssignment1/dataset_1.mat')
  unique_labels=np.unique(mats['labels'])
  unique_labels
  data=mats["samples"]
  labels=mats["labels"][0]
  classes_count=len(set(labels))
  data_shape=(28,28,1)
  plt.figure(figsize=(8,8))
  index=np.ones((10,10))
  pos=0
  for i in range (10):
    pos=0
    for j in range(len(labels)):
      if(i==labels[j]):
        if pos>9:
          break
        else:
          index[i][pos]=j
          pos+=1       
  m=0
  for i in range(10):
    for j in range(10):
      m+=1
      plt.subplot(10,10,m)
      plt.xticks([])
      plt.yticks([])
      plt.grid(False)
      plt.imshow(np.squeeze(data[int(index[i][j])]), cmap=plt.cm.binary)
      plt.xlabel(unique_labels[i])
  plt.tight_layout()   
  plt.show()
q1a()

def q1b():

  import matplotlib.pyplot as plt
  from matplotlib import cm
  import numpy as np
  from scipy.io import loadmat

  mats2=loadmat('/content/drive/My Drive/Colab Notebooks/MLAssignment1/dataset_2.mat')
  unique_labels2=np.unique(mats2['labels'])
  unique_labels2
  labels2=mats2["labels"][0]
  data2=mats2['samples']
  x=np.zeros(20000)
  y=np.zeros(20000)
  for i in range(len(labels2)):
    x[i]=data2[i][0]
    y[i]=data2[i][1]
  plt.figure(figsize=(10,6))
  plt.scatter(x,y,c=mats2["labels"],label="Dataset_2",cmap=plt.cm.get_cmap("jet",4),marker='o')
  plt.colorbar(ticks=range(4))
  plt.xlabel("samples_0th_index")
  plt.ylabel("samples_1st_index")
  plt.legend(loc="upper left")
  plt.show() 
q1b()

def q1c_tsne():
  from sklearn.manifold import TSNE
  from sklearn.preprocessing import StandardScaler
  import matplotlib.pyplot as plt
  from matplotlib import cm
  import numpy as np
  from scipy.io import loadmat
  mats = loadmat('/content/drive/My Drive/Colab Notebooks/MLAssignment1/dataset_1.mat')
  unique_labels=np.unique(mats['labels'])
  unique_labels
  data=mats["samples"]
  labels=mats["labels"][0]
  #data_1000=data[0:1000,:]
  #labels_1000=labels[0:1000]
  tsne=TSNE(n_components=2, random_state=0)
  std_data=StandardScaler().fit_transform(data.reshape(50000,784))
  tsne_results = tsne.fit_transform(std_data)
  np.save("/content/drive/My Drive/Colab Notebooks/MLAssignment1/tsne_saved.npy",tsne_results)
#q1c_tsne()

def q1c_plot():
  import matplotlib.pyplot as plt
  from matplotlib import cm
  import numpy as np
  from scipy.io import loadmat
  mats = loadmat('/content/drive/My Drive/Colab Notebooks/MLAssignment1/dataset_1.mat')
  unique_labels=np.unique(mats['labels'])
  unique_labels
  data=mats["samples"]
  labels=mats["labels"][0]

  tsne_results=np.load("/content/drive/My Drive/Colab Notebooks/MLAssignment1/tsne_saved.npy")
  x=np.zeros(50000)
  y=np.zeros(50000)
  plt.figure(figsize=(20,12))
  x=tsne_results[:,0]
  y=tsne_results[:,1]
  plt.scatter(x,y,c=labels,label="dataset_1_2D",cmap=plt.cm.get_cmap("jet", 10),marker="o")
  plt.colorbar(ticks=range(10))
  plt.xlabel("TSNE_1st")
  plt.ylabel("TSNE_2nd")
  plt.legend(loc="upper left")
  plt.show()
q1c_plot()

def q1d_tsne():
  from sklearn.manifold import TSNE
  from mpl_toolkits import mplot3d
  from mpl_toolkits.mplot3d import Axes3D
  from sklearn.preprocessing import StandardScaler
  import matplotlib.pyplot as plt
  import numpy as np
  from scipy.io import loadmat

  mats = loadmat('/content/drive/My Drive/Colab Notebooks/MLAssignment1/dataset_1.mat')
  unique_labels=np.unique(mats['labels'])
  unique_labels
  data=mats["samples"]
  labels=mats["labels"][0]
  
  tsne2=TSNE(n_components=3, random_state=0)
  std_data2=StandardScaler().fit_transform(data.reshape(50000,784))
  #data_1000=mats["samples"][0:500,:]
  #labels_1000=labels[0:500]
  tsne_results2 = tsne2.fit_transform(std_data2)
  np.save("/content/drive/My Drive/Colab Notebooks/MLAssignment1/tsne2_saved.npy",tsne_results2)
  #tsne_results2 = tsne2.fit_transform(data_1000.reshape(500,784))
#q1d_tsne()

def q1d_plot():
  import matplotlib.pyplot as plt
  from matplotlib import cm
  import numpy as np
  from scipy.io import loadmat

  mats = loadmat('/content/drive/My Drive/Colab Notebooks/MLAssignment1/dataset_1.mat')
  unique_labels=np.unique(mats['labels'])
  unique_labels
  data=mats["samples"]
  labels=mats["labels"][0]

  tsne_results2=np.load("/content/drive/My Drive/Colab Notebooks/MLAssignment1/tsne2_saved.npy")
  x2=np.zeros(50000)
  y2=np.zeros(50000)
  z=np.zeros(50000)
  plt.figure(figsize=(20,15))
  #ax = plt.figure().add_subplot(111, projection='3d')
  ax = plt.axes(projection ="3d")
  y2=tsne_results2[:,0]
  x2=tsne_results2[:,1]
  z=tsne_results2[:,2]
  target=labels

  #scatter=ax.scatter(y2,x2,z,c=labels,cmap=plt.cm.get_cmap("gist_rainbow", 10),s=7,marker="o")
  scatter=ax.scatter(y2,x2,z,c=target,s=10,cmap=plt.cm.get_cmap("gist_rainbow", 10),marker='o')
  classes = ['0','1', '2', '3','4','5','6','7','8','9']
  legend=ax.legend(handles=scatter.legend_elements()[0], labels=classes,loc="upper left")
  ax.add_artist(legend)
  ax.set_xlabel('TSNE_1st-one')
  ax.set_ylabel('TSNE_2nd-two')
  ax.set_zlabel('TSNE_3rd-three')
  plt.title("dataset_1_3D")
  plt.show()
q1d_plot()

def Train_Test_Split(major, dataset_org, labels_org):
  import matplotlib.pyplot as plt
  from matplotlib import cm
  import numpy as np
  from scipy.io import loadmat
  ratio = int(major * dataset_org.shape[0])
  p=np.random.permutation(len(labels_org))
  #print(p)
  samples_shuffle=dataset_org[p]
  labels_shuffle=labels_org[p]
  samples_train=samples_shuffle[:ratio,:]
  labels_train=labels_shuffle[:ratio]
  samples_test=samples_shuffle[ratio:,:]
  labels_test=labels_shuffle[ratio:]
  return samples_train, labels_train, samples_test, labels_test

def Check_accuracy(predictions,groundTruth):
  import matplotlib.pyplot as plt
  from matplotlib import cm
  import numpy as np
  from scipy.io import loadmat
  truecount=0
  for i in range(len(predictions)):
    if (predictions[i]==groundTruth[i]):
      truecount+=1
  accuracy= truecount/len(predictions) 
  return accuracy    
def q2a_b():
  from sklearn.tree import DecisionTreeClassifier
  from sklearn.metrics import accuracy_score
  import matplotlib.pyplot as plt
  import pandas as pd
  import numpy as np
  from scipy.io import loadmat
  Test_score=list()
  mats2=loadmat('/content/drive/My Drive/Colab Notebooks/MLAssignment1/dataset_2.mat')
  unique_labels2=np.unique(mats2['labels'])
  unique_labels2
  labels2=mats2["labels"][0]
  data2=mats2['samples']
  samples_train, labels_train, samples_test, labels_test=Train_Test_Split(0.7,data2,labels2) 
  print(len(samples_train),len(samples_test),len(labels_train),len(labels_test))

  max_depth_range = list(range(1, 16))
  final_table1=pd.DataFrame(columns=['Depth','Train Accuracy','Test Accuracy'])

  for depth in max_depth_range:
    clf = DecisionTreeClassifier(max_depth = depth, random_state = 0)
    clf.fit(samples_train,labels_train)
    predicted_values_test=clf.predict(samples_test)
    predicted_values_train=clf.predict(samples_train)
    Test_accuracy_score=Check_accuracy(predicted_values_test,labels_test)
    Test_score.append(Test_accuracy_score)
    Train_accuracy_score=Check_accuracy(predicted_values_train,labels_train)
    new_row= {'Depth':depth,'Train Accuracy':Train_accuracy_score ,'Test Accuracy':Test_accuracy_score}
    final_table1=final_table1.append(new_row,ignore_index=True)
  print(final_table1) 
  plt.figure(figsize=(8,5))
  plt.plot(max_depth_range,Test_score,marker="o")
  plt.xlabel("Max_Depth")
  plt.ylabel(" Testing_Accuracy")
  plt.show()
q2a_b()

def Train_Test_Split(major, dataset_org, labels_org):
  import matplotlib.pyplot as plt
  from matplotlib import cm
  import numpy as np
  from scipy.io import loadmat
  ratio = int(major * dataset_org.shape[0])
  p=np.random.permutation(len(labels_org))
  #print(p)
  samples_shuffle=dataset_org[p]
  labels_shuffle=labels_org[p]
  samples_train=samples_shuffle[:ratio,:]
  labels_train=labels_shuffle[:ratio]
  samples_test=samples_shuffle[ratio:,:]
  labels_test=labels_shuffle[ratio:]
  return samples_train, labels_train, samples_test, labels_test

def Check_accuracy(predictions,groundTruth):
  import matplotlib.pyplot as plt
  from matplotlib import cm
  import numpy as np
  from scipy.io import loadmat
  truecount=0
  for i in range(len(predictions)):
    if (predictions[i]==groundTruth[i]):
      truecount+=1
  accuracy= truecount/len(predictions) 
  return accuracy
def q2c():
  from sklearn.metrics import accuracy_score
  from sklearn.tree import DecisionTreeClassifier
  from sklearn.metrics import accuracy_score
  import matplotlib.pyplot as plt
  import pandas as pd
  import numpy as np
  from scipy.io import loadmat
  Test_score=list()
  mats2=loadmat('/content/drive/My Drive/Colab Notebooks/MLAssignment1/dataset_2.mat')
  unique_labels2=np.unique(mats2['labels'])
  unique_labels2
  labels2=mats2["labels"][0]
  data2=mats2['samples']
  samples_train, labels_train, samples_test, labels_test=Train_Test_Split(0.7,data2,labels2) 
  print(len(samples_train),len(samples_test),len(labels_train),len(labels_test))
  max_depth_range = list(range(1, 16))
  final_table2=pd.DataFrame(columns=['Depth','Train Accuracy','Test Accuracy'])
  for depth in max_depth_range:
    clf2 = DecisionTreeClassifier(max_depth = depth, random_state = 0)
    clf2.fit(samples_train,labels_train)
    predicted_values_test=clf2.predict(samples_test)
    predicted_values_train=clf2.predict(samples_train)
    Test_accuracy_score_skl=accuracy_score(labels_test,predicted_values_test)
    Train_accuracy_score_skl=accuracy_score(labels_train,predicted_values_train)
    new_row= {'Depth':depth ,'Train Accuracy':Train_accuracy_score_skl ,'Test Accuracy':Test_accuracy_score_skl}
    final_table2=final_table2.append(new_row,ignore_index=True)
  print(final_table2)
q2c()

def Train_Test_Split(major, dataset_org, labels_org):
  import matplotlib.pyplot as plt
  from matplotlib import cm
  import numpy as np
  from scipy.io import loadmat
  ratio = int(major * dataset_org.shape[0])
  p=np.random.permutation(len(labels_org))
  #print(p)
  samples_shuffle=dataset_org[p]
  labels_shuffle=labels_org[p]
  samples_train=samples_shuffle[:ratio,:]
  labels_train=labels_shuffle[:ratio]
  samples_test=samples_shuffle[ratio:,:]
  labels_test=labels_shuffle[ratio:]
  return samples_train, labels_train, samples_test, labels_test
def q3a_b():
  from sklearn.tree import DecisionTreeClassifier
  from sklearn.metrics import accuracy_score
  import pandas as pd
  import numpy as np
  #preprocessing()
  input_data=pd.read_csv("/content/drive/My Drive/Colab Notebooks/MLAssignment1/PRSA_data_2010.1.1-2014.12.31.csv")
  type(input_data)
  cbwd=input_data['cbwd']
  unique_cbwd=np.unique(cbwd)
  print(unique_cbwd)
  print("\n")
  from sklearn.preprocessing import LabelEncoder
  lb_cbwd=LabelEncoder()
  input_data['cbwd']=lb_cbwd.fit_transform(input_data['cbwd'])
  input_data.drop(["No"],axis=1,inplace=True)
  input_data=input_data.fillna(input_data.mean())
  labels3=input_data['month']
  input_features=input_data.drop(['month'],axis=1)
  print(input_data.head(10))
  print("\n")
  print(input_features.head(10))
  print("\n")

  samples_train3, labels_train3, samples_test3, labels_test3=Train_Test_Split(0.8,input_features.to_numpy(),labels3.to_numpy())
  print(len(samples_train3),len(samples_test3),len(labels_train3),len(labels_test3))
  print("\n")
  clf3 = DecisionTreeClassifier(criterion="gini")
  labels_train3=labels_train3.astype('uint8')
  clf3.fit(samples_train3,labels_train3)
  predicted_values_test3=clf3.predict(samples_test3)
  Test_accuracy_score3=accuracy_score(labels_test3,predicted_values_test3)
  print( "Performance criteria = gini " , Test_accuracy_score3)
  clf4 = DecisionTreeClassifier(criterion="entropy")
  clf4.fit(samples_train3,labels_train3)
  predicted_values_test3a=clf4.predict(samples_test3)
  Test_accuracy_score3a=accuracy_score(labels_test3,predicted_values_test3a)
  print( "Performance criteria = entropy ", Test_accuracy_score3a)
  print("\n")

  max_depth_range3 = list([2,3,4,8,10,15,30])
  Test_score3b=list()
  Train_score3b=list()
  final_table3=pd.DataFrame(columns=['Depth','Train Accuracy','Test Accuracy'])
  for depth in max_depth_range3:
    clf5 = DecisionTreeClassifier(max_depth=depth,criterion="entropy")
    clf5.fit(samples_train3,labels_train3)
    predicted_values_test3b=clf5.predict(samples_test3)
    predicted_values_train3b=clf5.predict(samples_train3)
    Test_accuracy_score3b=accuracy_score(labels_test3,predicted_values_test3b)
    Test_score3b.append(Test_accuracy_score3b)
    Train_accuracy_score3b=accuracy_score(labels_train3,predicted_values_train3b)
    Train_score3b.append(Train_accuracy_score3b)
    new_row= {'Depth':depth,'Train Accuracy':Train_accuracy_score3b ,'Test Accuracy':Test_accuracy_score3b}
    final_table3=final_table3.append(new_row,ignore_index=True)
  print(final_table3)
  print("\n")
  #train test plot
  import numpy as np
  import matplotlib.pyplot as plt
  from matplotlib import cm
  plt.figure(figsize=(8,5))
  plt.plot(max_depth_range3,Test_score3b,label="Test accuracy",marker="o")
  plt.plot(max_depth_range3,Train_score3b,label="Train accuracy",marker="o")
  plt.xlabel("Max_Depth")
  plt.ylabel(" Testing_Accuracy")
  plt.legend(loc="upper left")
  plt.show()
q3a_b()

def Train_Test_Split(major, dataset_org, labels_org):
  import matplotlib.pyplot as plt
  from matplotlib import cm
  import numpy as np
  from scipy.io import loadmat
  ratio = int(major * dataset_org.shape[0])
  p=np.random.permutation(len(labels_org))
  #print(p)
  samples_shuffle=dataset_org[p]
  labels_shuffle=labels_org[p]
  samples_train=samples_shuffle[:ratio,:]
  labels_train=labels_shuffle[:ratio]
  samples_test=samples_shuffle[ratio:,:]
  labels_test=labels_shuffle[ratio:]
  return samples_train, labels_train, samples_test, labels_test
  
def q3c():
  from sklearn.tree import DecisionTreeClassifier
  from sklearn.metrics import accuracy_score
  from collections import Counter 
  from statistics import mode
  import pandas as pd
  import numpy as np
  #preprocessing()
  input_data=pd.read_csv("/content/drive/My Drive/Colab Notebooks/MLAssignment1/PRSA_data_2010.1.1-2014.12.31.csv")
  type(input_data)
  cbwd=input_data['cbwd']
  unique_cbwd=np.unique(cbwd)
  #print(unique_cbwd)
  from sklearn.preprocessing import LabelEncoder
  lb_cbwd=LabelEncoder()
  input_data['cbwd']=lb_cbwd.fit_transform(input_data['cbwd'])
  input_data.drop(["No"],axis=1,inplace=True)
  input_data=input_data.fillna(input_data.mean())
  labels3=input_data['month']
  input_features=input_data.drop(['month'],axis=1)
  #print(input_data.head(10))
  #print(input_features.head(10))

  predicted_array={}
  samples_train3c, labels_train3c, samples_test3c, labels_test3c=Train_Test_Split(0.8,input_features.to_numpy(),labels3.to_numpy())

  for i in range(1,101):
    p=np.random.permutation(len(labels_train3c))
    samples_shuffle_train3c=samples_train3c[p]
    labels_shuffle_train3c=labels_train3c[p]
    ratio=int(0.5*samples_train3c.shape[0])
    random_samples_train3c=samples_shuffle_train3c[:ratio,:]
    random_labels_train3c=labels_shuffle_train3c[:ratio]
    clf3c = DecisionTreeClassifier(max_depth = 3, random_state = 0,criterion="entropy")
    clf3c.fit(random_samples_train3c,random_labels_train3c)
    predicted_values_test3c=clf3c.predict(samples_test3c)
    predicted_array[i]=predicted_values_test3c
  column=np.zeros(100)
  major=np.zeros(8765)
  #for majority vote
  for j in range(0,len(labels_test3c)):
    for k in range(0,100):
      column[k]=list(predicted_array.values())[k][j]
    #major[j]=mode(column)
    temp=Counter(column)
    major[j],x =temp.most_common(1)[0]   
  majority_accuracy=accuracy_score(labels_test3c,major.astype(int))
  print( "depth = 3"," ", "Test accuracy=", majority_accuracy)
     
q3c()

def Train_Test_Split(major, dataset_org, labels_org):
  import matplotlib.pyplot as plt
  from matplotlib import cm
  import numpy as np
  from scipy.io import loadmat
  ratio = int(major * dataset_org.shape[0])
  p=np.random.permutation(len(labels_org))
  #print(p)
  samples_shuffle=dataset_org[p]
  labels_shuffle=labels_org[p]
  samples_train=samples_shuffle[:ratio,:]
  labels_train=labels_shuffle[:ratio]
  samples_test=samples_shuffle[ratio:,:]
  labels_test=labels_shuffle[ratio:]
  return samples_train, labels_train, samples_test, labels_test
  
def q3d():
  from sklearn.tree import DecisionTreeClassifier
  from sklearn.metrics import accuracy_score
  from collections import Counter 
  from statistics import mode
  import pandas as pd
  import numpy as np
  #preprocessing()
  input_data=pd.read_csv("/content/drive/My Drive/Colab Notebooks/MLAssignment1/PRSA_data_2010.1.1-2014.12.31.csv")
  type(input_data)
  cbwd=input_data['cbwd']
  unique_cbwd=np.unique(cbwd)
  print(unique_cbwd)
  from sklearn.preprocessing import LabelEncoder
  lb_cbwd=LabelEncoder()
  input_data['cbwd']=lb_cbwd.fit_transform(input_data['cbwd'])
  input_data.drop(["No"],axis=1,inplace=True)
  input_data=input_data.fillna(input_data.mean())
  labels3=input_data['month']
  input_features=input_data.drop(['month'],axis=1)
  #print(input_data.head(10))
  #print(input_features.head(10))

  predicted_array={}
  samples_train3c, labels_train3c, samples_test3c, labels_test3c=Train_Test_Split(0.8,input_features.to_numpy(),labels3.to_numpy())

  max_depth_range3c = list([4,8,10,15,20,30])
  number_of_stumps=list([100,150,200,250,300])
  majority_accuracy_list=list()
  predicted_train_array={}
  srno=0
  final_table=pd.DataFrame(columns=['Srno','Depth','Number of Trees','Train Accuracy','Test Accuracy'])
  for depth in max_depth_range3c:
    for total_stumps in number_of_stumps:
      for i in range(total_stumps):
        p=np.random.permutation(len(labels_train3c))
        samples_shuffle_train3c=samples_train3c[p]
        labels_shuffle_train3c=labels_train3c[p]
        ratio=int(0.5*samples_train3c.shape[0])
        random_samples_train3c=samples_shuffle_train3c[:ratio,:]
        random_labels_train3c=labels_shuffle_train3c[:ratio]
        clf3c = DecisionTreeClassifier(max_depth = depth, random_state = 0,criterion="entropy")
        clf3c.fit(random_samples_train3c,random_labels_train3c)
        predicted_values_test3c=clf3c.predict(samples_test3c)
        predicted_values_train3c=clf3c.predict(samples_train3c)
        predicted_array[i]=predicted_values_test3c
        predicted_train_array[i]=predicted_values_train3c
      column=np.zeros(total_stumps)
      column_train=np.zeros(total_stumps)
      major=np.zeros(len(labels_test3c))
      major_train=np.zeros(len(labels_train3c))
      #for majority vote-test data
      for j in range(0,len(labels_test3c)):
        for k in range(total_stumps):
          column[k]=list(predicted_array.values())[k][j]
        #major[j]=mode(column)
        temp=Counter(column)
        major[j],x =temp.most_common(1)[0] 
      #for training data   
      for j in range(0,len(samples_train3c)):
        for k in range(total_stumps):
          column_train[k]=list(predicted_train_array.values())[k][j]
        #major[j]=mode(column)
        temp=Counter(column_train)
        major_train[j],x =temp.most_common(1)[0]   
      majority_accuracy=accuracy_score(labels_test3c,major.astype(int))
      majority_accuracy_train=accuracy_score(labels_train3c,major_train.astype(int))
      srno+=1
      new_row= {'Srno':srno,'Depth':depth,'Number of Trees':total_stumps ,'Train Accuracy':majority_accuracy_train ,'Test Accuracy':majority_accuracy}
      final_table=final_table.append(new_row,ignore_index=True)
  print(final_table)
q3d()

